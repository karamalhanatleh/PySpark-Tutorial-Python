{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80344ce",
   "metadata": {},
   "source": [
    "# PySpark Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d9389da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import paskages\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9722234b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2b3a0bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a SparkSession with the application name \"Dataframe\"\n",
    "spark =SparkSession.builder.appName(\"Dataframe\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "25288ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Desktop-2001:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Dataframe</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1f03d01ca60>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1486bb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: string, Experience: string]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read dataset\n",
    "df_pyspark = spark.read.option(\"header\",'true').csv(\"text2.csv\")# it doesn't infer the data types of the columns; all columns will be treated as strings.\n",
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9c843866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+\n",
      "|    Name|Age|Experience|\n",
      "+--------+---+----------+\n",
      "|   Krish| 31|        10|\n",
      "|sudanshu| 30|         8|\n",
      "|   sunny| 29|         4|\n",
      "+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fa1f3359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check is schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb389101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "36466f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: int, Experience: int]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read dataset\n",
    "\n",
    "df_pyspark = spark.read.option(\"header\",'true').csv(\"text2.csv\" , inferSchema=True)#option tells PySpark to automatically infer the data types of each column in the DataFrame\n",
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "631a0bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+\n",
      "|    Name|Age|Experience|\n",
      "+--------+---+----------+\n",
      "|   Krish| 31|        10|\n",
      "|sudanshu| 30|         8|\n",
      "|   sunny| 29|         4|\n",
      "+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a382536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check is schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef9a171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8f72c601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: int, Experience: int]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read dataset\n",
    "#specifies   first row of  CSV file contains column names.\n",
    "df_pyspark = spark.read.option(\"header\",'true').csv(\"text2.csv\" , inferSchema=True ,header=True)\n",
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3a90b44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+\n",
      "|    Name|Age|Experience|\n",
      "+--------+---+----------+\n",
      "|   Krish| 31|        10|\n",
      "|sudanshu| 30|         8|\n",
      "|   sunny| 29|         4|\n",
      "+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f109b261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check is schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa25fbf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "df49e2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print type\n",
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "70a97274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'Experience']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#name columns\n",
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "39012b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Krish', Age=31, Experience=10),\n",
       " Row(Name='sudanshu', Age=30, Experience=8),\n",
       " Row(Name='sunny', Age=29, Experience=4)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print head data 3 \n",
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0e766f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+\n",
      "|    Name|Age|Experience|\n",
      "+--------+---+----------+\n",
      "|   Krish| 31|        10|\n",
      "|sudanshu| 30|         8|\n",
      "|   sunny| 29|         4|\n",
      "+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e622a083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.select(\"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c169dff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark.select(\"Name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "971e4254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|    Name|Experience|\n",
      "+--------+----------+\n",
      "|   Krish|        10|\n",
      "|sudanshu|         8|\n",
      "|   sunny|         4|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['Name','Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501da783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e5a6d679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----+-----------------+\n",
      "|summary| Name| Age|       Experience|\n",
      "+-------+-----+----+-----------------+\n",
      "|  count|    3|   3|                3|\n",
      "|   mean| NULL|30.0|7.333333333333333|\n",
      "| stddev| NULL| 1.0|3.055050463303893|\n",
      "|    min|Krish|  29|                4|\n",
      "|    max|sunny|  31|               10|\n",
      "+-------+-----+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check describe\n",
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef634f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2904c9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+-----------------------+\n",
      "|    Name|Age|Experience|Experience After 2 year|\n",
      "+--------+---+----------+-----------------------+\n",
      "|   Krish| 31|        10|                     12|\n",
      "|sudanshu| 30|         8|                     10|\n",
      "|   sunny| 29|         4|                      6|\n",
      "+--------+---+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adding columns in data frame\n",
    "df_pyspark = df_pyspark.withColumn(\"Experience After 2 year\",df_pyspark['Experience']+2)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3a139b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns \n",
    "df_pyspark = df_pyspark.drop('Experience After 2 year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "767694ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+\n",
      "|    Name|Age|Experience|\n",
      "+--------+---+----------+\n",
      "|   Krish| 31|        10|\n",
      "|sudanshu| 30|         8|\n",
      "|   sunny| 29|         4|\n",
      "+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e9776b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7fe3d988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+\n",
      "|New Name|Age|Experience|\n",
      "+--------+---+----------+\n",
      "|   Krish| 31|        10|\n",
      "|sudanshu| 30|         8|\n",
      "|   sunny| 29|         4|\n",
      "+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rename columns\n",
    "df_pyspark.withColumnRenamed(\"Name\",'New Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70530cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d411dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3dc2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "69b1ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24e2aaa",
   "metadata": {},
   "source": [
    "##### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8012660a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+\n",
      "|    Name|Age|Experience|\n",
      "+--------+---+----------+\n",
      "|   Krish| 31|        10|\n",
      "|sudanshu| 30|         8|\n",
      "|   sunny| 29|         4|\n",
      "+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "39fecbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+\n",
      "|    Name|Age|Experience|\n",
      "+--------+---+----------+\n",
      "|   Krish| 34|        10|\n",
      "|sudanshu| 33|         8|\n",
      "|   sunny| 32|         4|\n",
      "+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumn(\"Age\",df_pyspark['Age']+3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc75d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be9517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624c8510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9d0b10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
